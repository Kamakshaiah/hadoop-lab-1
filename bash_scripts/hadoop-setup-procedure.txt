
# install java

sudo apt-get install default-jre default-jdk 
java -version

sudo update-alternatives --display java [to know java home directory]
sudo update-alternatives --config java

export JAVA_HOME=/usr/lib/jvm/java-7-openjdk 
export PATH=$PATH:/usr/lib/jvm/java-7-openjdk/bin

# hadoop user group

sudo addgroup hadoop [groupdel hadoop]
sudo adduser --ingroup hadoop hduser [sudo deluser hduser hadoop]

sudo su root 
sudo gedit etc/sudoers

hduser ALL=(ALL:ALL) ALL [add this line just below root]

# setup localhost and lan

sudo apt-get install openssh-server 
sudo su hduser 
ssh-keygen -t rsa -P "" 
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys

# setup hadoop

sudo mv /home/Desktop/your..hadoop..folder/ /usr/local/hadoop
sudo chown hduser:hadoop -R /usr/local/hadoop

sudo mkdir -p /usr/local/hadoop_tmp/hdfs/namenode 
sudo mkdir -p /usr/local/hadoop_tmp/hdfs/datanode 
sudo chown hduser:hadoop -R /usr/local/hadoop_tmp/

# Configuring Hadoop

## bashrc

export JAVA_HOME=/usr/lib/jvm/java-8-oracle 
export HADOOP_HOME=/usr/local/hadoop 
export PATH=$PATH:$HADOOP_HOME/bin 
export PATH=$PATH:$HADOOP_HOME/sbin 
export HADOOP_MAPRED_HOME=$HADOOP_HOME 
export HADOOP_HDFS_HOME=$HADOOP_HOME 
export YARN_HOME=$HADOOP_HOME 
export HADOOP_COMMON_LIB_NATIVE_DIRECTORY=$HADOOP_HOME/lib/native 
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib" 
export PATH=$PATH:/usr/local/hadoop/bin

## hadoop-env.sh

JAVA_HOME = $(JAVA_HOME)

## core-site.xml

<property> 
<name>fs.default.name</name> 
<value>hdfs://localhost:9000</value> 
</property>

## hdfs-site.xml

<property> 
<name>dfs.replication</name> 
<value>1</value> 
</property> 
<property> 
<name>dfs.namenode.name.dir</name> 
<value>file:/usr/local/hadoop_tmp/hdfs/namenode</value> 
</property> 
<property> 
<name>dfs.datanode.data.dir</name> 
<value>file:/usr/local/hadoop_tmp/hdfs/datanode</value> 
</property>

## yarn-site.xml

<property> 
<name>yarn.nodemanager.aux-services</name> 
<value>mapreduce_shuffle</value> 
</property> 
<property> 
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name> 
<value>org.apache.hadoop.mapred.ShuffleHandler</value> 
</property>

## mapred-site.xml

<property> 
<name>mapreduce.framework.name</name> 
<value>yarn</value> 
</property>

## format namenode

hdfs namenode -format

## start hadoop

start-dfs.sh 
start-yarn.sh